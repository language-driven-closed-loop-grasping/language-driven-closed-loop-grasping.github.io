<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Language-Driven Closed-Loop Grasping with Model-Predictive
    Trajectory Replanning</title>
  <link rel="icon" type="image/x-icon" href="static/pdfs/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Language-Driven Closed-Loop Grasping with Model-Predictive
              Trajectory Replanning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=T_LryjgAAAAJ&hl=en" target="_blank">Huy Hoang Nguyen</a><sup>1*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                <span class="author-block">
                  <a href="https://scholar.google.de/citations?user=H0GgsQ4AAAAJ&hl=de" target="_blank">Florian Beck</a><sup>2*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=qyExc4QAAAAJ&hl=en" target="_blank">Minh Nhat Vu</a><sup>2,4**</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=PH_GwWwAAAAJ&hl=de" target="_blank">Gerald Ebmer</a><sup>2</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <span class="author-block">
                    <a href="https://www.csc.liv.ac.uk/~anguyen/" target="_blank">Anh Nguyen</a><sup>3</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=ee4tJYgAAAAJ&hl=en" target="_blank">Andreas Kugi</a><sup>2,4</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Eötvös Loránd University</span>&nbsp;&nbsp;
                    <span class="author-block"><sup>2</sup>ACIN - TU Wien</span>&nbsp;&nbsp;
                    <span class="author-block"><sup>3</sup>University of Liverpool</span>&nbsp;&nbsp;
                    <span class="author-block"><sup>4</sup>Austrian Institute of Technology</span>&nbsp;&nbsp;
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution</small></span>&nbsp;&nbsp;
                    <span class="eql-cntrb"><small><br><sup>**</sup>Corresponding Author</small></span>
                  </div>
                  <div class="logo-container">
                    <img
                      src="./static/images/elte_angol_fekvo_kek_logo.jpg" />
                    <img src="./static/images/acin-tuw.png" />
                    <img src="./static/images/images.png" />
                    <img
                      src="./static/images/ait_logo_ohne_claim_c1_rgb.jpg" />
                  </div>
                  <!-- <div class="column has-text-centered">
                    <div class="publication-links"> -->
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://youtu.be/PAODfJkVXJo" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-youtube"></i>
                      </span>
                      <span>Video</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Combining a vision module inside a closed-loop control system for a seamless movement of a robot in a manipulation task is challenging due to the inconsistent update rates between utilized modules. This is even more difficult in a dynamic environment, e.g., objects are moving. 
            This paper presents a modular zero-shot framework for language-driven manipulation of (dynamic) objects through a closed-loop control system with real-time trajectory replanning and an online 6D object pose localization. 
            By leveraging a vision language model via natural language commands, an object is segmented within 0.5s. 
            Then, guided by natural language commands, a closed-loop system, including a unified pose estimation and tracking and online trajectory planning, is utilized to continuously track this object and compute the optimal trajectory in real time. This provides a smooth trajectory that avoids jerky movements and ensures the robot can grasp a non-stationary object. Experiment results exhibit the real-time capability of the proposed zero-shot modular framework for the trajectory optimization module to accurately and efficiently grasp moving objects, i.e., up to 30Hz update rates for the online 6D pose localization module and 10Hz update rates for the receding-horizon trajectory optimization. This highlights the modular framework's potential applications in robotics and human-robot interaction.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper video. -->
<div class="columns is-centered has-text-centered">
  <div class="column is-two-thirds">
    <h2 class="title is-3">Video</h2>
    <div class="publication-video">
      <iframe src="https://youtu.be/PAODfJkVXJo"
        frameborder="0" allow="encrypted-media" allowfullscreen></iframe>
    </div>
  </div>
</div>
</section>
<!-- End teaser video -->

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Experiment</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-blue-block">
          <video poster="" id="blue-block" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/RAL-blue-block.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-metal">
          <video poster="" id="metal" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video-RAL-submission_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-orange-block">
          <video poster="" id="orange-block" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video-RAL-submission_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-plier">
          <video poster="" id="plier" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video-RAL-submission_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-scissor">
          <video poster="" id="scissor" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video-RAL-submission_4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-stripper">
          <video poster="" id="stripper" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video-RAL-submission_5.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-timer">
          <video poster="" id="timer" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video-RAL-submission_6.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-eraser">
          <video poster="" id="eraser" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video-RAL-submission_7.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-black-tool">
          <video poster="" id="black-tool" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video-RAL-submission_8.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-drill">
          <video poster="" id="drill" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video-RAL-submission_9.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-silver-block">
          <video poster="" id="silver-block" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video-RAL-submission_10.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-widescreen">

    <div class="rows">

      <!-- Animation. -->
      <div class="rows is-centered ">
        <div class="row is-full-width">

            <!--/ Results. -->
            <h2 class="title is-3">Results</h2>

            <div class="container">
              <div class="columns is-vcentered  is-centered">
                <img src="./static/images/result.png" alt="results" />
                </br>
              </div>
              <br>
              <h2 class="subtitle has-text-centered">
                Results from our method show that the 3D position trajectory of the object closely matches the ground truth measurements(Opitrack). It is important to note that these measurements are transformed to the camera origin, which is approximately
                1 m away from the object. The maximum positional error observed is approximately 0.02 m, representing 2% relative
                to the distance to the camera. The orientation error is constrained, with a maximum error of 0.15 rad in the roll angle.
              </h2>
            </div>

            <br>
            <br>

</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<section class="section" id="acknowledgements">
  <div class="container content is-max-desktop">
    <h2 class="title">Acknowledgements</h2>
    <p>We borrow the page template from  <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. Special thanks to them!
      <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
      Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
  </div>
</section>

  <!-- <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            We borrow the page template from  <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. Special thanks to them!
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
